2025-06-27 12:46:21,029 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:46:21,030 - energy_eval - INFO - Using device: cpu
2025-06-27 12:46:21,030 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:46:21,052 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:46:21,052 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:46:21,052 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {}
++++++++++++++++++++++++++++++
2025-06-27 12:46:21,171 - energy_eval - INFO - Completed smollm:135m in 0h 0m 0s
2025-06-27 12:46:21,171 - energy_eval - INFO - 
============================================================
Experiment completed in 0h 0m 0s
============================================================
2025-06-27 12:48:30,037 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {False, 'q'}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:48:30,037 - energy_eval - INFO - Using device: cpu
2025-06-27 12:48:30,038 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:48:30,043 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:48:30,043 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:48:30,043 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {False, 'q'}
++++++++++++++++++++++++++++++
2025-06-27 12:48:30,043 - energy_eval - ERROR - Critical error: 'set' object has no attribute 'items'
Traceback (most recent call last):
  File "/home/s72kw/Documents/LMPowerConsuption/src/experiment.py", line 382, in <module>
    run()
  File "/home/s72kw/Documents/LMPowerConsuption/src/experiment.py", line 58, in run
    for mode_tag, include_passage in model_modes.items():
                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'set' object has no attribute 'items'
2025-06-27 12:49:22,504 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {False, 'q'}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:49:22,504 - energy_eval - INFO - Using device: cpu
2025-06-27 12:49:22,504 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:49:22,510 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:49:22,510 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:49:22,510 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {False, 'q'}
++++++++++++++++++++++++++++++
2025-06-27 12:49:22,510 - energy_eval - ERROR - Critical error: 'set' object has no attribute 'items'
Traceback (most recent call last):
  File "/home/s72kw/Documents/LMPowerConsuption/src/experiment.py", line 382, in <module>
    run()
  File "/home/s72kw/Documents/LMPowerConsuption/src/experiment.py", line 58, in run
    for mode_tag, include_passage in model_modes.items():
                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'set' object has no attribute 'items'
2025-06-27 12:51:31,622 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q': False}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:51:31,622 - energy_eval - INFO - Using device: cpu
2025-06-27 12:51:31,622 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:51:31,628 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:51:31,628 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:51:31,628 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-06-27 12:53:09,159 - energy_eval - WARNING - Experiment interrupted by user
2025-06-27 12:53:49,271 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q': False, 'q+r': True}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:53:49,272 - energy_eval - INFO - Using device: cpu
2025-06-27 12:53:49,272 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:53:49,277 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:53:49,277 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:53:49,277 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-27 12:54:33,492 - energy_eval - WARNING - Experiment interrupted by user
2025-06-27 12:55:11,275 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q': False, 'q+r': True}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:55:11,275 - energy_eval - INFO - Using device: cpu
2025-06-27 12:55:11,275 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:55:11,280 - energy_eval - ERROR - Dataset loading failed: Expecting value: line 2 column 1 (char 1)
2025-06-27 12:58:42,403 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q': False, 'q+r': True}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:58:42,404 - energy_eval - INFO - Using device: cpu
2025-06-27 12:58:42,404 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:58:42,547 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:58:42,547 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:58:42,547 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-27 12:58:53,576 - energy_eval - ERROR - Error processing sample 0: name 'CONGFIG' is not defined
2025-06-27 12:58:59,299 - energy_eval - WARNING - Experiment interrupted by user
2025-06-27 12:59:17,900 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q': False, 'q+r': True}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 12:59:17,900 - energy_eval - INFO - Using device: cpu
2025-06-27 12:59:17,900 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 12:59:17,905 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 12:59:17,905 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 12:59:17,905 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-27 13:01:21,759 - energy_eval - INFO - Completed q mode for smollm:135m
2025-06-27 13:04:20,952 - energy_eval - WARNING - Experiment interrupted by user
2025-06-27 13:10:45,364 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'smollm:135m': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=8, device='cpu', modes={'smollm:135m': {'q+r': True}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 13:10:45,364 - energy_eval - INFO - Using device: cpu
2025-06-27 13:10:45,364 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 13:10:45,369 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 13:10:45,369 - energy_eval - INFO - 
============================================================
Running model: smollm:135m
============================================================
2025-06-27 13:10:45,369 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-27 13:16:47,863 - energy_eval - INFO - Loaded Wikipedia corpus and indexes
2025-06-27 13:24:00,698 - energy_eval - WARNING - Experiment interrupted by user
2025-06-27 13:25:51,871 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=PosixPath('data/hotpot_wiki-processed'), corpus_cache=PosixPath('cache/wiki.pkl'), tfidf_cache=PosixPath('cache/tfidf.pkl'), index_cache=PosixPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results/energy'), result_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/results'), data_dir=PosixPath('/home/s72kw/Documents/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-27 13:25:51,872 - energy_eval - INFO - Using device: cpu
2025-06-27 13:25:51,872 - energy_eval - INFO - Loading dataset from /home/s72kw/Documents/LMPowerConsuption/data/boolq_mini_128.jsonl
2025-06-27 13:25:51,916 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-27 13:25:51,916 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-27 13:25:51,916 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-27 15:49:05,510 - energy_eval - INFO - Completed q mode for deepseek-r1:8b
2025-06-27 15:55:02,228 - energy_eval - INFO - Loaded Wikipedia corpus and indexes
2025-06-28 05:20:14,777 - energy_eval - INFO - Completed q+r mode for deepseek-r1:8b
2025-06-28 05:26:23,032 - energy_eval - INFO - Completed deepseek-r1:8b in 16h 0m 31s
2025-06-28 05:26:23,077 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:14b
============================================================
2025-06-28 05:26:23,077 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 09:59:30,872 - energy_eval - INFO - Completed q mode for deepseek-r1:14b
2025-06-28 10:05:48,801 - energy_eval - INFO - Loaded Wikipedia corpus and indexes
2025-06-28 10:06:03,808 - energy_eval - ERROR - Error processing sample 0: model requires more system memory (10.5 GiB) than is available (9.7 GiB) (status code: 500)
2025-06-28 10:06:14,453 - energy_eval - ERROR - Error processing sample 1: model requires more system memory (10.5 GiB) than is available (9.7 GiB) (status code: 500)
2025-06-28 10:06:25,040 - energy_eval - ERROR - Error processing sample 2: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:06:35,597 - energy_eval - ERROR - Error processing sample 3: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:06:46,246 - energy_eval - ERROR - Error processing sample 4: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:06:56,821 - energy_eval - ERROR - Error processing sample 5: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:07:07,397 - energy_eval - ERROR - Error processing sample 6: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:07:17,976 - energy_eval - ERROR - Error processing sample 7: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:07:28,597 - energy_eval - ERROR - Error processing sample 8: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:07:39,198 - energy_eval - ERROR - Error processing sample 9: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:07:49,790 - energy_eval - ERROR - Error processing sample 10: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:08:00,453 - energy_eval - ERROR - Error processing sample 11: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:08:11,027 - energy_eval - ERROR - Error processing sample 12: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:08:21,625 - energy_eval - ERROR - Error processing sample 13: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:08:32,242 - energy_eval - ERROR - Error processing sample 14: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:08:42,825 - energy_eval - ERROR - Error processing sample 15: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:08:53,453 - energy_eval - ERROR - Error processing sample 16: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:04,034 - energy_eval - ERROR - Error processing sample 17: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:14,617 - energy_eval - ERROR - Error processing sample 18: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:25,246 - energy_eval - ERROR - Error processing sample 19: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:35,812 - energy_eval - ERROR - Error processing sample 20: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:46,403 - energy_eval - ERROR - Error processing sample 21: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:09:56,987 - energy_eval - ERROR - Error processing sample 22: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:10:07,591 - energy_eval - ERROR - Error processing sample 23: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:10:18,167 - energy_eval - ERROR - Error processing sample 24: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:10:28,791 - energy_eval - ERROR - Error processing sample 25: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:10:39,369 - energy_eval - ERROR - Error processing sample 26: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:10:49,985 - energy_eval - ERROR - Error processing sample 27: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:00,617 - energy_eval - ERROR - Error processing sample 28: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:11,233 - energy_eval - ERROR - Error processing sample 29: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:21,811 - energy_eval - ERROR - Error processing sample 30: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:32,428 - energy_eval - ERROR - Error processing sample 31: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:43,042 - energy_eval - ERROR - Error processing sample 32: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:11:53,656 - energy_eval - ERROR - Error processing sample 33: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:12:04,235 - energy_eval - ERROR - Error processing sample 34: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:12:15,038 - energy_eval - ERROR - Error processing sample 35: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:12:25,605 - energy_eval - ERROR - Error processing sample 36: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:12:36,194 - energy_eval - ERROR - Error processing sample 37: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:12:46,820 - energy_eval - ERROR - Error processing sample 38: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:12:57,406 - energy_eval - ERROR - Error processing sample 39: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:13:07,998 - energy_eval - ERROR - Error processing sample 40: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:13:18,558 - energy_eval - ERROR - Error processing sample 41: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:13:29,203 - energy_eval - ERROR - Error processing sample 42: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:13:39,812 - energy_eval - ERROR - Error processing sample 43: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:13:50,393 - energy_eval - ERROR - Error processing sample 44: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:00,973 - energy_eval - ERROR - Error processing sample 45: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:11,577 - energy_eval - ERROR - Error processing sample 46: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:22,160 - energy_eval - ERROR - Error processing sample 47: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:32,753 - energy_eval - ERROR - Error processing sample 48: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:43,335 - energy_eval - ERROR - Error processing sample 49: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:14:53,926 - energy_eval - ERROR - Error processing sample 50: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:04,519 - energy_eval - ERROR - Error processing sample 51: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:15,125 - energy_eval - ERROR - Error processing sample 52: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:25,706 - energy_eval - ERROR - Error processing sample 53: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:36,285 - energy_eval - ERROR - Error processing sample 54: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:46,878 - energy_eval - ERROR - Error processing sample 55: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:15:57,464 - energy_eval - ERROR - Error processing sample 56: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:16:08,063 - energy_eval - ERROR - Error processing sample 57: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:16:18,660 - energy_eval - ERROR - Error processing sample 58: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:16:29,432 - energy_eval - ERROR - Error processing sample 59: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:16:40,030 - energy_eval - ERROR - Error processing sample 60: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:16:50,649 - energy_eval - ERROR - Error processing sample 61: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:17:01,260 - energy_eval - ERROR - Error processing sample 62: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:17:11,840 - energy_eval - ERROR - Error processing sample 63: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:17:22,428 - energy_eval - ERROR - Error processing sample 64: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:17:33,018 - energy_eval - ERROR - Error processing sample 65: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:17:43,606 - energy_eval - ERROR - Error processing sample 66: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:17:54,188 - energy_eval - ERROR - Error processing sample 67: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:18:04,815 - energy_eval - ERROR - Error processing sample 68: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:18:15,410 - energy_eval - ERROR - Error processing sample 69: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:18:25,995 - energy_eval - ERROR - Error processing sample 70: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:18:36,605 - energy_eval - ERROR - Error processing sample 71: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:18:47,398 - energy_eval - ERROR - Error processing sample 72: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:18:57,978 - energy_eval - ERROR - Error processing sample 73: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:19:08,553 - energy_eval - ERROR - Error processing sample 74: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:19:19,174 - energy_eval - ERROR - Error processing sample 75: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:19:29,752 - energy_eval - ERROR - Error processing sample 76: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:19:40,327 - energy_eval - ERROR - Error processing sample 77: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:19:50,907 - energy_eval - ERROR - Error processing sample 78: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:20:01,488 - energy_eval - ERROR - Error processing sample 79: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:20:12,062 - energy_eval - ERROR - Error processing sample 80: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:20:22,657 - energy_eval - ERROR - Error processing sample 81: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:20:33,272 - energy_eval - ERROR - Error processing sample 82: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:20:44,020 - energy_eval - ERROR - Error processing sample 83: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:20:54,594 - energy_eval - ERROR - Error processing sample 84: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:05,215 - energy_eval - ERROR - Error processing sample 85: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:15,790 - energy_eval - ERROR - Error processing sample 86: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:26,392 - energy_eval - ERROR - Error processing sample 87: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:36,970 - energy_eval - ERROR - Error processing sample 88: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:47,598 - energy_eval - ERROR - Error processing sample 89: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:21:58,178 - energy_eval - ERROR - Error processing sample 90: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:22:08,763 - energy_eval - ERROR - Error processing sample 91: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:22:19,324 - energy_eval - ERROR - Error processing sample 92: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:22:29,965 - energy_eval - ERROR - Error processing sample 93: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:22:40,546 - energy_eval - ERROR - Error processing sample 94: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:22:51,308 - energy_eval - ERROR - Error processing sample 95: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:23:01,900 - energy_eval - ERROR - Error processing sample 96: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:23:12,516 - energy_eval - ERROR - Error processing sample 97: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:23:23,104 - energy_eval - ERROR - Error processing sample 98: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:23:33,703 - energy_eval - ERROR - Error processing sample 99: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:23:44,298 - energy_eval - ERROR - Error processing sample 100: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:23:54,863 - energy_eval - ERROR - Error processing sample 101: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:05,458 - energy_eval - ERROR - Error processing sample 102: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:16,087 - energy_eval - ERROR - Error processing sample 103: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:26,680 - energy_eval - ERROR - Error processing sample 104: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:37,275 - energy_eval - ERROR - Error processing sample 105: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:47,853 - energy_eval - ERROR - Error processing sample 106: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:24:58,497 - energy_eval - ERROR - Error processing sample 107: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:25:09,315 - energy_eval - ERROR - Error processing sample 108: model requires more system memory (10.5 GiB) than is available (9.8 GiB) (status code: 500)
2025-06-28 10:25:19,870 - energy_eval - ERROR - Error processing sample 109: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:25:30,449 - energy_eval - ERROR - Error processing sample 110: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:25:41,017 - energy_eval - ERROR - Error processing sample 111: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:25:51,592 - energy_eval - ERROR - Error processing sample 112: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:02,191 - energy_eval - ERROR - Error processing sample 113: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:13,097 - energy_eval - ERROR - Error processing sample 114: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:23,802 - energy_eval - ERROR - Error processing sample 115: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:34,395 - energy_eval - ERROR - Error processing sample 116: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:45,037 - energy_eval - ERROR - Error processing sample 117: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:26:55,610 - energy_eval - ERROR - Error processing sample 118: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:06,177 - energy_eval - ERROR - Error processing sample 119: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:16,760 - energy_eval - ERROR - Error processing sample 120: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:27,340 - energy_eval - ERROR - Error processing sample 121: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:37,948 - energy_eval - ERROR - Error processing sample 122: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:48,539 - energy_eval - ERROR - Error processing sample 123: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:27:59,122 - energy_eval - ERROR - Error processing sample 124: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:28:09,704 - energy_eval - ERROR - Error processing sample 125: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:28:20,331 - energy_eval - ERROR - Error processing sample 126: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:28:30,905 - energy_eval - ERROR - Error processing sample 127: model requires more system memory (10.5 GiB) than is available (9.9 GiB) (status code: 500)
2025-06-28 10:28:30,905 - energy_eval - INFO - Completed q+r mode for deepseek-r1:14b
2025-06-28 10:28:36,626 - energy_eval - INFO - Completed deepseek-r1:14b in 5h 2m 13s
2025-06-28 10:28:36,626 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-06-28 10:28:36,626 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-06-28 14:30:44,857 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 14:30:44,857 - energy_eval - INFO - Using device: cpu
2025-06-28 14:30:44,857 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 14:30:44,873 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 14:30:44,873 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-28 14:30:44,873 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 14:31:55,119 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 14:32:22,093 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q': False, 'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 14:32:22,093 - energy_eval - INFO - Using device: cpu
2025-06-28 14:32:22,093 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 14:32:22,093 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 14:32:22,093 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-28 14:32:22,093 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {}
++++++++++++++++++++++++++++++
2025-06-28 14:32:22,157 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 0m 0s
2025-06-28 14:32:22,157 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 14:32:22,157 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 14:32:22,157 - energy_eval - INFO - Completed q mode for deepseek-r1:8b
2025-06-28 14:34:16,264 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 14:34:40,003 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q': False, 'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 14:34:40,003 - energy_eval - INFO - Using device: cpu
2025-06-28 14:34:40,003 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 14:34:40,003 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 14:34:40,003 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-28 14:34:40,003 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {}
++++++++++++++++++++++++++++++
2025-06-28 14:34:40,084 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 0m 0s
2025-06-28 14:34:40,084 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 14:34:40,084 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 15:10:35,453 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 15:12:11,351 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 15:12:11,351 - energy_eval - INFO - Using device: cpu
2025-06-28 15:12:11,351 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 15:12:11,351 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 15:12:11,351 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 15:12:11,351 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 15:12:48,170 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 15:12:58,511 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 15:12:58,511 - energy_eval - INFO - Using device: cpu
2025-06-28 15:12:58,511 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 15:12:58,526 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 15:12:58,526 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 15:12:58,526 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 15:16:38,062 - energy_eval - INFO - Loaded Wikipedia corpus and indexes
2025-06-28 15:18:01,652 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 15:30:09,956 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 15:30:09,957 - energy_eval - INFO - Using device: cpu
2025-06-28 15:30:09,957 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 15:30:09,964 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 15:30:09,964 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 15:30:09,965 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 15:34:11,075 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 4, 1)
2025-06-28 16:35:22,735 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 16:36:30,234 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 16:36:30,235 - energy_eval - INFO - Using device: cpu
2025-06-28 16:36:30,235 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 16:36:30,238 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 16:36:30,238 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 16:36:30,239 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 16:40:19,226 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 48)
2025-06-28 17:09:00,142 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 17:39:19,549 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read the following passage carefully and answer the question with only one word. It must be 'True' or 'False'.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer the following question with only one word. It must be 'True' or 'False'.\nQuestion: {question}\nAnswer:"}})
2025-06-28 17:39:19,549 - energy_eval - INFO - Using device: cpu
2025-06-28 17:39:19,549 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 17:39:19,556 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 17:39:19,556 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 17:39:19,557 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 17:43:26,918 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 4, 7)
2025-06-28 20:26:50,772 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-06-28 20:26:50,773 - energy_eval - INFO - Using device: cpu
2025-06-28 20:26:50,773 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 20:26:50,777 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 20:26:50,777 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 20:26:50,777 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 20:30:48,193 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 57)
2025-06-28 20:31:25,887 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 20:42:14,444 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:8b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:8b': {'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-06-28 20:42:14,444 - energy_eval - INFO - Using device: cpu
2025-06-28 20:42:14,444 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 20:42:14,448 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 20:42:14,448 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 20:42:14,448 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 20:46:10,485 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 56)
2025-06-28 21:04:11,179 - energy_eval - INFO - Completed q+r mode for deepseek-r1:8b
2025-06-28 21:04:17,828 - energy_eval - INFO - Completed deepseek-r1:8b in 0h 22m 3s
2025-06-28 21:04:17,828 - energy_eval - INFO - 
============================================================
Experiment completed in 0h 22m 3s
============================================================
2025-06-28 21:23:36,983 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-06-28 21:23:36,983 - energy_eval - INFO - Using device: cpu
2025-06-28 21:23:36,983 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 21:23:36,987 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 21:23:36,988 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-28 21:23:36,988 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 21:32:18,709 - energy_eval - INFO - Completed q mode for deepseek-r1:7b
2025-06-28 21:36:33,118 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 4, 14)
2025-06-28 21:55:34,659 - energy_eval - INFO - Completed q+r mode for deepseek-r1:7b
2025-06-28 21:55:41,389 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 32m 4s
2025-06-28 21:55:41,390 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 21:55:41,390 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 21:58:28,799 - energy_eval - WARNING - Experiment interrupted by user
2025-06-28 23:47:01,290 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-06-28 23:47:01,290 - energy_eval - INFO - Using device: cpu
2025-06-28 23:47:01,290 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-06-28 23:47:01,294 - energy_eval - INFO - Loaded dataset with 128 samples
2025-06-28 23:47:01,294 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-28 23:47:01,294 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 23:47:01,296 - energy_eval - INFO - Completed q mode for deepseek-r1:7b
2025-06-28 23:50:41,009 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 39)
2025-06-28 23:50:41,011 - energy_eval - INFO - Completed q+r mode for deepseek-r1:7b
2025-06-28 23:50:45,040 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 3m 43s
2025-06-28 23:50:45,040 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-28 23:50:45,040 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-28 23:57:07,414 - energy_eval - INFO - Completed q mode for deepseek-r1:8b
2025-06-29 00:00:47,559 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 40)
2025-06-29 00:17:18,729 - energy_eval - INFO - Completed q+r mode for deepseek-r1:8b
2025-06-29 00:17:22,936 - energy_eval - INFO - Completed deepseek-r1:8b in 0h 26m 37s
2025-06-29 00:17:22,936 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:14b
============================================================
2025-06-29 00:17:22,936 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-29 00:17:22,947 - energy_eval - INFO - Completed q mode for deepseek-r1:14b
2025-06-29 00:21:06,078 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 43)
2025-06-29 00:43:03,629 - energy_eval - INFO - Completed q+r mode for deepseek-r1:14b
2025-06-29 00:43:15,936 - energy_eval - INFO - Completed deepseek-r1:14b in 0h 25m 52s
2025-06-29 00:43:15,936 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-06-29 00:43:15,936 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-06-29 00:50:31,536 - energy_eval - INFO - Completed q mode for deepseek-r1:32b
2025-06-29 00:50:31,623 - energy_eval - INFO - Completed deepseek-r1:32b in 0h 7m 15s
2025-06-29 00:50:31,623 - energy_eval - INFO - 
============================================================
Experiment completed in 1h 3m 30s
============================================================
2025-06-29 09:26:33,327 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.com', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-06-29 09:26:33,327 - energy_eval - INFO - Using device: cpu
2025-06-29 09:26:35,059 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-06-29 09:26:35,059 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-06-29 09:26:35,059 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-29 12:42:46,197 - energy_eval - INFO - Completed q mode for deepseek-r1:7b
2025-06-29 12:46:37,931 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 51)
2025-06-29 19:42:26,162 - energy_eval - INFO - Completed q+r mode for deepseek-r1:7b
2025-06-29 19:42:38,631 - energy_eval - INFO - Completed deepseek-r1:7b in 10h 16m 3s
2025-06-29 19:42:38,631 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-06-29 19:42:38,631 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-29 23:52:42,674 - energy_eval - INFO - Completed q mode for deepseek-r1:8b
2025-06-29 23:56:25,633 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 42)
2025-06-30 07:28:13,044 - energy_eval - INFO - Completed q+r mode for deepseek-r1:8b
2025-06-30 07:28:25,725 - energy_eval - INFO - Completed deepseek-r1:8b in 11h 45m 47s
2025-06-30 07:28:25,726 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:14b
============================================================
2025-06-30 07:28:25,726 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-06-30 12:04:34,348 - energy_eval - INFO - Completed q mode for deepseek-r1:14b
2025-06-30 12:08:17,705 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 43)
2025-06-30 22:32:38,073 - energy_eval - INFO - Completed q+r mode for deepseek-r1:14b
2025-06-30 22:32:51,072 - energy_eval - INFO - Completed deepseek-r1:14b in 15h 4m 25s
2025-06-30 22:32:51,072 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-06-30 22:32:51,072 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-01 04:33:46,985 - energy_eval - INFO - Completed q mode for deepseek-r1:32b
2025-07-01 04:33:47,436 - energy_eval - INFO - Completed deepseek-r1:32b in 6h 0m 56s
2025-07-01 04:33:47,436 - energy_eval - INFO - 
============================================================
Experiment completed in 43h 7m 14s
============================================================
2025-07-01 10:37:57,215 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-01 10:37:57,215 - energy_eval - INFO - Using device: cpu
2025-07-01 10:37:58,001 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-01 10:37:58,001 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-07-01 10:37:58,001 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-01 18:20:05,555 - energy_eval - INFO - Completed q mode for deepseek-r1:7b
2025-07-01 18:24:05,392 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in (0, 3, 59)
2025-07-02 08:32:50,387 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-02 08:32:50,388 - energy_eval - INFO - Using device: cpu
2025-07-02 08:32:51,112 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-02 08:32:51,112 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-07-02 08:32:51,112 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-02 08:32:51,125 - energy_eval - INFO - Completed q mode for deepseek-r1:7b in 0h 0m 0s
2025-07-02 08:36:32,445 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0h 3m 41s
2025-07-02 08:48:51,055 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:272b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-02 08:48:51,056 - energy_eval - INFO - Using device: cpu
2025-07-02 08:48:52,588 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-07-02 08:48:52,589 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-02 08:48:52,589 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-02 13:22:34,900 - energy_eval - INFO - Completed q mode for gemma3:1b in 4h 33m 42s
2025-07-02 13:26:37,786 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0h 4m 2s
2025-07-02 19:53:03,111 - energy_eval - INFO - Completed q+r mode for gemma3:1b in 6h 26m 25s
2025-07-02 19:53:33,124 - energy_eval - INFO - Completed gemma3:1b in 11h 4m 40s
2025-07-02 19:53:33,124 - energy_eval - INFO - 
============================================================
Running model: gemma3:4b
============================================================
2025-07-02 19:53:33,124 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-03 01:09:48,209 - energy_eval - INFO - Completed q mode for gemma3:4b in 5h 16m 15s
2025-07-03 01:13:32,556 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0h 3m 44s
2025-07-03 09:08:38,572 - energy_eval - INFO - Completed q+r mode for gemma3:4b in 7h 55m 6s
2025-07-03 09:08:53,813 - energy_eval - INFO - Completed gemma3:4b in 13h 15m 20s
2025-07-03 09:08:53,813 - energy_eval - INFO - 
============================================================
Running model: gemma3:12b
============================================================
2025-07-03 09:08:53,813 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-03 15:27:30,365 - energy_eval - INFO - Completed q mode for gemma3:12b in 6h 18m 36s
2025-07-03 15:31:29,506 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0h 3m 59s
2025-07-03 15:32:06,925 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-03 15:32:06,926 - energy_eval - INFO - Using device: cpu
2025-07-03 15:32:08,475 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-07-03 15:32:08,475 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-03 15:32:08,475 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-03 15:32:08,485 - energy_eval - INFO - Completed q mode for gemma3:1b in 0:00:00
2025-07-03 15:35:50,089 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:41
2025-07-03 15:35:50,094 - energy_eval - INFO - Completed q+r mode for gemma3:1b in 0:00:00
2025-07-03 15:35:54,648 - energy_eval - INFO - Completed gemma3:1b in 0h 3m 46s
2025-07-03 15:35:54,648 - energy_eval - INFO - 
============================================================
Running model: gemma3:4b
============================================================
2025-07-03 15:35:54,648 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-03 15:35:54,653 - energy_eval - INFO - Completed q mode for gemma3:4b in 0:00:00
2025-07-03 15:39:41,734 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:47
2025-07-03 15:39:41,743 - energy_eval - INFO - Completed q+r mode for gemma3:4b in 0:00:00
2025-07-03 15:39:45,992 - energy_eval - INFO - Completed gemma3:4b in 0h 3m 51s
2025-07-03 15:39:45,992 - energy_eval - INFO - 
============================================================
Running model: gemma3:12b
============================================================
2025-07-03 15:39:45,992 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-03 15:39:45,997 - energy_eval - INFO - Completed q mode for gemma3:12b in 0:00:00
2025-07-03 15:43:30,584 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:44
2025-07-04 02:46:46,881 - energy_eval - INFO - Completed q+r mode for gemma3:12b in 11:03:16
2025-07-04 02:46:59,640 - energy_eval - INFO - Completed gemma3:12b in 11h 7m 13s
2025-07-04 02:46:59,640 - energy_eval - INFO - 
============================================================
Running model: gemma3:27b
============================================================
2025-07-04 02:46:59,640 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-04 10:09:00,267 - energy_eval - INFO - Completed q mode for gemma3:27b in 7:22:00
2025-07-04 10:09:00,492 - energy_eval - INFO - Completed gemma3:27b in 7h 22m 0s
2025-07-04 10:09:00,492 - energy_eval - INFO - 
============================================================
Experiment completed in 18h 36m 53s
============================================================
2025-07-04 10:59:32,207 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-04 10:59:32,207 - energy_eval - INFO - Using device: cpu
2025-07-04 10:59:32,207 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\boolq_mini_128.jsonl
2025-07-04 10:59:32,219 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-04 10:59:32,219 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-04 10:59:32,219 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 11:14:05,749 - energy_eval - INFO - Completed q mode for gemma3:1b in 0:14:33
2025-07-04 11:18:09,031 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:04:03
2025-07-04 11:36:24,763 - energy_eval - INFO - Completed q+r mode for gemma3:1b in 0:18:15
2025-07-04 11:36:39,417 - energy_eval - INFO - Completed gemma3:1b in 0h 37m 7s
2025-07-04 11:36:39,417 - energy_eval - INFO - 
============================================================
Running model: gemma3:4b
============================================================
2025-07-04 11:36:39,417 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 11:51:39,179 - energy_eval - INFO - Completed q mode for gemma3:4b in 0:14:59
2025-07-04 11:55:33,871 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:54
2025-07-04 12:16:43,937 - energy_eval - INFO - Completed q+r mode for gemma3:4b in 0:21:10
2025-07-04 12:16:50,343 - energy_eval - INFO - Completed gemma3:4b in 0h 40m 10s
2025-07-04 12:16:50,343 - energy_eval - INFO - 
============================================================
Running model: gemma3:12b
============================================================
2025-07-04 12:16:50,343 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 12:33:03,459 - energy_eval - INFO - Completed q mode for gemma3:12b in 0:16:13
2025-07-04 12:37:01,346 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:57
2025-07-04 13:05:57,146 - energy_eval - INFO - Completed q+r mode for gemma3:12b in 0:28:55
2025-07-04 13:06:03,893 - energy_eval - INFO - Completed gemma3:12b in 0h 49m 13s
2025-07-04 13:06:03,893 - energy_eval - INFO - 
============================================================
Running model: gemma3:27b
============================================================
2025-07-04 13:06:03,893 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-04 13:24:43,221 - energy_eval - INFO - Completed q mode for gemma3:27b in 0:18:39
2025-07-04 13:24:43,370 - energy_eval - INFO - Completed gemma3:27b in 0h 18m 39s
2025-07-04 13:24:43,370 - energy_eval - INFO - 
============================================================
Experiment completed in 2h 25m 11s
============================================================
2025-07-04 15:32:01,872 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-04 15:32:01,872 - energy_eval - INFO - Using device: cpu
2025-07-04 15:32:02,800 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-04 15:32:02,800 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-04 15:32:02,800 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 15:33:04,870 - energy_eval - WARNING - Experiment interrupted by user
2025-07-04 15:33:54,493 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-04 15:33:54,493 - energy_eval - INFO - Using device: cpu
2025-07-04 15:33:55,191 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-04 15:33:55,191 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-04 15:33:55,191 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 22:52:34,076 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cpu', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-04 22:52:34,076 - energy_eval - INFO - Using device: cpu
2025-07-04 22:52:34,076 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-04 22:52:34,096 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-04 22:52:34,096 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-04 22:52:34,096 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 23:05:53,033 - energy_eval - INFO - Completed q mode for gemma3:1b in 0:13:18
2025-07-04 23:09:31,754 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:38
2025-07-04 23:32:33,142 - energy_eval - INFO - Completed q+r mode for gemma3:1b in 0:23:01
2025-07-04 23:32:36,937 - energy_eval - INFO - Completed gemma3:1b in 0h 40m 2s
2025-07-04 23:32:36,938 - energy_eval - INFO - 
============================================================
Running model: gemma3:4b
============================================================
2025-07-04 23:32:36,938 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-04 23:45:54,759 - energy_eval - INFO - Completed q mode for gemma3:4b in 0:13:17
2025-07-04 23:49:31,692 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:36
2025-07-05 00:12:47,186 - energy_eval - INFO - Completed q+r mode for gemma3:4b in 0:23:15
2025-07-05 00:12:51,301 - energy_eval - INFO - Completed gemma3:4b in 0h 40m 14s
2025-07-05 00:12:51,301 - energy_eval - INFO - 
============================================================
Running model: gemma3:12b
============================================================
2025-07-05 00:12:51,301 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 00:26:31,528 - energy_eval - INFO - Completed q mode for gemma3:12b in 0:13:40
2025-07-05 00:30:09,141 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:37
2025-07-05 00:53:45,805 - energy_eval - INFO - Completed q+r mode for gemma3:12b in 0:23:36
2025-07-05 00:53:50,086 - energy_eval - INFO - Completed gemma3:12b in 0h 40m 58s
2025-07-05 00:53:50,086 - energy_eval - INFO - 
============================================================
Running model: gemma3:27b
============================================================
2025-07-05 00:53:50,086 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-05 01:07:40,756 - energy_eval - INFO - Completed q mode for gemma3:27b in 0:13:50
2025-07-05 01:07:40,851 - energy_eval - INFO - Completed gemma3:27b in 0h 13m 50s
2025-07-05 01:07:40,851 - energy_eval - INFO - 
============================================================
Experiment completed in 2h 15m 6s
============================================================
2025-07-05 08:01:51,116 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:1.5b': 'ollama', 'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-05 08:01:51,116 - energy_eval - INFO - Using device: cuda
2025-07-05 08:01:51,116 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-05 08:01:51,135 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-05 08:01:51,135 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:1.5b
============================================================
2025-07-05 08:01:51,135 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 08:10:44,561 - energy_eval - WARNING - Experiment interrupted by user
2025-07-05 08:10:50,333 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:1.5b': 'ollama', 'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-05 08:10:50,333 - energy_eval - INFO - Using device: cuda
2025-07-05 08:10:50,333 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-05 08:10:50,346 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-05 08:10:50,346 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:1.5b
============================================================
2025-07-05 08:10:50,346 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 08:15:18,624 - energy_eval - INFO - Completed q mode for deepseek-r1:1.5b in 0:04:28
2025-07-05 08:20:17,640 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:04:59
2025-07-05 08:22:09,384 - energy_eval - ERROR - Error processing sample 10: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:22:19,017 - energy_eval - ERROR - Error processing sample 11: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:22:28,825 - energy_eval - ERROR - Error processing sample 12: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:22:38,595 - energy_eval - ERROR - Error processing sample 13: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:22:48,439 - energy_eval - ERROR - Error processing sample 14: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:22:58,176 - energy_eval - ERROR - Error processing sample 15: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:07,974 - energy_eval - ERROR - Error processing sample 16: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:17,719 - energy_eval - ERROR - Error processing sample 17: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:27,586 - energy_eval - ERROR - Error processing sample 18: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:37,375 - energy_eval - ERROR - Error processing sample 19: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:47,235 - energy_eval - ERROR - Error processing sample 20: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:23:56,934 - energy_eval - ERROR - Error processing sample 21: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:24:06,760 - energy_eval - ERROR - Error processing sample 22: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:24:16,453 - energy_eval - ERROR - Error processing sample 23: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:24:26,112 - energy_eval - ERROR - Error processing sample 24: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-05 08:24:41,510 - energy_eval - WARNING - Experiment interrupted by user
2025-07-05 08:25:00,317 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:1.5b': 'ollama', 'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-05 08:25:00,317 - energy_eval - INFO - Using device: cuda
2025-07-05 08:25:00,317 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-05 08:25:00,331 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-05 08:25:00,331 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:1.5b
============================================================
2025-07-05 08:25:00,331 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 08:25:00,333 - energy_eval - INFO - Completed q mode for deepseek-r1:1.5b in 0:00:00
2025-07-05 08:28:42,812 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:42
2025-07-05 08:49:06,891 - energy_eval - INFO - Completed q+r mode for deepseek-r1:1.5b in 0:20:24
2025-07-05 08:49:12,136 - energy_eval - INFO - Completed deepseek-r1:1.5b in 0h 24m 11s
2025-07-05 08:49:12,137 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-07-05 08:49:12,137 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 09:01:14,694 - energy_eval - INFO - Completed q mode for deepseek-r1:7b in 0:12:02
2025-07-05 09:05:01,448 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:46
2025-07-05 09:27:03,564 - energy_eval - INFO - Completed q+r mode for deepseek-r1:7b in 0:22:02
2025-07-05 09:27:07,712 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 37m 55s
2025-07-05 09:27:07,712 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-07-05 09:27:07,712 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 09:39:07,055 - energy_eval - INFO - Completed q mode for deepseek-r1:8b in 0:11:59
2025-07-05 09:41:10,111 - energy_eval - WARNING - Experiment interrupted by user
2025-07-05 09:41:30,152 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:1.5b': 'ollama', 'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-05 09:41:30,153 - energy_eval - INFO - Using device: cuda
2025-07-05 09:41:30,153 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-05 09:41:30,171 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-05 09:41:30,171 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:1.5b
============================================================
2025-07-05 09:41:30,171 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 09:41:30,179 - energy_eval - INFO - Completed q mode for deepseek-r1:1.5b in 0:00:00
2025-07-05 09:45:10,718 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:40
2025-07-05 09:45:10,720 - energy_eval - INFO - Completed q+r mode for deepseek-r1:1.5b in 0:00:00
2025-07-05 09:45:14,775 - energy_eval - INFO - Completed deepseek-r1:1.5b in 0h 3m 44s
2025-07-05 09:45:14,775 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-07-05 09:45:14,775 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 09:45:14,777 - energy_eval - INFO - Completed q mode for deepseek-r1:7b in 0:00:00
2025-07-05 09:48:54,057 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:39
2025-07-05 09:48:54,059 - energy_eval - INFO - Completed q+r mode for deepseek-r1:7b in 0:00:00
2025-07-05 09:48:58,158 - energy_eval - INFO - Completed deepseek-r1:7b in 0h 3m 43s
2025-07-05 09:48:58,158 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:8b
============================================================
2025-07-05 09:48:58,158 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 09:48:58,160 - energy_eval - INFO - Completed q mode for deepseek-r1:8b in 0:00:00
2025-07-05 09:52:37,221 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:39
2025-07-05 10:14:55,809 - energy_eval - INFO - Completed q+r mode for deepseek-r1:8b in 0:22:18
2025-07-05 10:15:00,085 - energy_eval - INFO - Completed deepseek-r1:8b in 0h 26m 1s
2025-07-05 10:15:00,085 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:14b
============================================================
2025-07-05 10:15:00,085 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-05 10:27:26,294 - energy_eval - INFO - Completed q mode for deepseek-r1:14b in 0:12:26
2025-07-05 10:31:07,955 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:41
2025-07-05 10:53:46,269 - energy_eval - INFO - Completed q+r mode for deepseek-r1:14b in 0:22:38
2025-07-05 10:53:50,388 - energy_eval - INFO - Completed deepseek-r1:14b in 0h 38m 50s
2025-07-05 10:53:50,388 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-07-05 10:53:50,388 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-05 11:06:24,188 - energy_eval - INFO - Completed q mode for deepseek-r1:32b in 0:12:33
2025-07-05 11:06:24,264 - energy_eval - INFO - Completed deepseek-r1:32b in 0h 12m 33s
2025-07-05 11:06:24,264 - energy_eval - INFO - 
============================================================
Experiment completed in 1h 24m 54s
============================================================
2025-07-06 19:28:02,309 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:1.5b': 'ollama', 'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:1.5b': {'q': False, 'q+r': True}, 'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-06 19:28:02,309 - energy_eval - INFO - Using device: cuda
2025-07-06 19:28:03,233 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-06 19:28:03,233 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:1.5b
============================================================
2025-07-06 19:28:03,233 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-06 19:29:51,528 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:7b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama', 'deepseek-r1:32b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:7b': {'q': False, 'q+r': True}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}, 'deepseek-r1:32b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-06 19:29:51,528 - energy_eval - INFO - Using device: cuda
2025-07-06 19:29:52,419 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-06 19:29:52,419 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:7b
============================================================
2025-07-06 19:29:52,420 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-06 19:29:52,441 - energy_eval - INFO - Completed q mode for deepseek-r1:7b in 0:00:00
2025-07-06 19:31:13,207 - energy_eval - WARNING - Experiment interrupted by user
2025-07-06 19:31:32,772 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='hotpot_mini_128.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-06 19:31:32,772 - energy_eval - INFO - Using device: cuda
2025-07-06 19:31:32,772 - energy_eval - INFO - Loading dataset from C:\Users\Ethan\Documents\PhD\LMPowerConsuption\data\hotpot_mini_128.jsonl
2025-07-06 19:31:32,798 - energy_eval - INFO - Loaded dataset with 128 samples
2025-07-06 19:31:32,798 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-06 19:31:32,798 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-06 19:31:32,807 - energy_eval - INFO - Completed q mode for gemma3:1b in 0:00:00
2025-07-06 19:32:59,247 - energy_eval - WARNING - Experiment interrupted by user
2025-07-06 19:33:05,579 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'gemma3:1b': 'ollama', 'gemma3:4b': 'ollama', 'gemma3:12b': 'ollama', 'gemma3:27b': 'ollama'}, dataset_name='hotpotqa/hotpot_qa', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'gemma3:1b': {'q': False, 'q+r': True}, 'gemma3:4b': {'q': False, 'q+r': True}, 'gemma3:12b': {'q': False, 'q+r': True}, 'gemma3:27b': {'q': False}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-06 19:33:05,579 - energy_eval - INFO - Using device: cuda
2025-07-06 19:33:06,273 - energy_eval - INFO - Loaded dataset with 7405 samples
2025-07-06 19:33:06,273 - energy_eval - INFO - 
============================================================
Running model: gemma3:1b
============================================================
2025-07-06 19:33:06,273 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False, 'q+r': True}
++++++++++++++++++++++++++++++
2025-07-07 07:28:32,448 - energy_eval - INFO - Completed q mode for gemma3:1b in 11:55:26
2025-07-07 07:32:21,634 - energy_eval - INFO - Loaded Wikipedia corpus and indexes in 0:03:49
2025-07-07 08:33:36,503 - energy_eval - WARNING - Experiment interrupted by user
2025-07-07 14:14:58,129 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:32b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:32b': {'q': False}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-07 14:14:58,129 - energy_eval - INFO - Using device: cuda
2025-07-07 14:14:59,723 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-07-07 14:14:59,723 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-07-07 14:14:59,723 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-07 14:15:56,911 - energy_eval - ERROR - Error processing sample 4: 'EmissionsTracker' object has no attribute 'final_emissions_data'
2025-07-07 14:17:16,639 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:32b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:32b': {'q': False}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-07 14:17:16,639 - energy_eval - INFO - Using device: cuda
2025-07-07 14:17:18,731 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-07-07 14:17:18,731 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-07-07 14:17:18,731 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
2025-07-07 14:22:15,688 - energy_eval - INFO - Starting experiment with config:
ExperimentConfig(model_types={'deepseek-r1:32b': 'ollama', 'deepseek-r1:8b': 'ollama', 'deepseek-r1:14b': 'ollama'}, dataset_name='google/boolq', dataset_file='boolq_1.jsonl', config='fullwiki', split='validation', n_samples=None, max_new_tokens=64, batch_size=4, device='cuda', modes={'deepseek-r1:32b': {'q': False}, 'deepseek-r1:8b': {'q': False, 'q+r': True}, 'deepseek-r1:14b': {'q': False, 'q+r': True}}, wiki_dir=WindowsPath('data/hotpot_wiki-processed'), corpus_cache=WindowsPath('cache/wiki.pkl'), tfidf_cache=WindowsPath('cache/tfidf.pkl'), index_cache=WindowsPath('cache/index.pkl'), intro_min_chars=51, hash_bits=20, token_pattern='(?u)\\b\\w+\\b', energy_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results/energy'), result_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/results'), data_dir=WindowsPath('C:/Users/Ethan/Documents/PhD/LMPowerConsuption/data'), retrieval_only=False, email_results=True, from_email='eheavey626@gmail.com', to_email='s72kw@unb.ca', log_level='INFO', prompt_templates={'hotpot': {'with_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know and the context provided. Context: {context}\nQuestion: {question}\nAnswer:', 'without_context': 'Answer the following to the best of your ability. You must provide an answer. If you are unsure, make an educated guess based on what you know. Question: {question}\nAnswer:'}, 'boolq': {'with_context': "Read this passage, then answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\n\nPassage: {context}\nQuestion: {question}\nAnswer:", 'without_context': "Answer ONLY with 'True' or 'False'. No explanations. No punctuation. Just one word.\nQuestion: {question}\nAnswer:"}})
2025-07-07 14:22:15,688 - energy_eval - INFO - Using device: cuda
2025-07-07 14:22:17,074 - energy_eval - INFO - Loaded dataset with 3270 samples
2025-07-07 14:22:17,074 - energy_eval - INFO - 
============================================================
Running model: deepseek-r1:32b
============================================================
2025-07-07 14:22:17,074 - energy_eval - INFO - 
++++++++++++++++++++++++++++++
Running modes: {'q': False}
++++++++++++++++++++++++++++++
